{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Имеющаяся ситуации:** на данный момент имеются рабочие модели, которые успешно классифицируют запросы пользователей по таким темам как \"Обещанный платеж\", \"Куда делись деньги\", \"Как подключить интернет\", \"Хочу поменять тариф\", и т.д.\n",
    "\n",
    "**Задача:** Углубить обработку запросов пользователей в чат-боте технической поддержки и категоризировать их по заданным, более узким в отличии от уже работающих, критериям.\n",
    "\n",
    "Далее представлены конкретные задачи от заказчика.\n",
    "\n",
    "---\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;}\n",
    ".tg .tg-lboi{border-color:inherit;text-align:left;vertical-align:middle}\n",
    ".tg .tg-0lax{text-align:left;vertical-align:top}\n",
    ".tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\" style=\"undefined;table-layout: fixed; width: 759px\">\n",
    "<colgroup>\n",
    "<col style=\"width: 27px\">\n",
    "<col style=\"width: 125px\">\n",
    "<col style=\"width: 105px\">\n",
    "<col style=\"width: 171px\">\n",
    "<col style=\"width: 331px\">\n",
    "</colgroup>\n",
    "  <tr>\n",
    "    <th class=\"tg-lboi\">№</th>\n",
    "    <th class=\"tg-lboi\">Запрос пользователя</th>\n",
    "    <th class=\"tg-0lax\">Результат текущего фреймворка</th>\n",
    "    <th class=\"tg-0lax\">Требуемый результат</th>\n",
    "    <th class=\"tg-0lax\"><center>Комментарий</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-lboi\">1</td>\n",
    "    <td class=\"tg-lboi\">Подключен ли у меня мобильный интернет</td>\n",
    "    <td class=\"tg-0lax\">Как подключить интернет</td>\n",
    "    <td class=\"tg-0lax\">Классифицировать как \"подключен ли мобильный интернет\"</td>\n",
    "    <td class=\"tg-0lax\">Создадим новый классификатор \"Подключен ли \\ Есть ли\" на том же уровне что и классификатор \"Хочу отключить услугу/опцию/подписку\". Частицу \"ли\" будем добавлять к слову перед ней. Модель будет обрабатывать запросы на получение информации.<br>Далее запрос будет классифицироваться на наличие в нем названия услуги</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-lboi\">2</td>\n",
    "    <td class=\"tg-lboi\">Не ноступен обещенный платеж. Почему</td>\n",
    "    <td class=\"tg-0lax\">Обещанный платеж</td>\n",
    "    <td class=\"tg-0lax\">Из фразы понятен контекст: \"Почему не доступен ОП\"</td>\n",
    "    <td class=\"tg-0lax\">Решение: Не менять модель, а просто после классификации в \"Обещанный платеж\" проверять содержание сообщения на предмет слов \"Почему\", \"не доступен\" и подобных.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">3</td>\n",
    "    <td class=\"tg-0pky\">За что сегодня снялись 15р?</td>\n",
    "    <td class=\"tg-0lax\">Куда делись деньги</td>\n",
    "    <td class=\"tg-0lax\">\"Начисления за подписка: 21.10.2019 - 15р\"</td>\n",
    "    <td class=\"tg-0lax\">Простое решение, которое приходит в голову - после классификации искать в тексте исходного запроса слова \"сегодня\", \"вчера\" и даты, а так же суммы. Можно так же искать и только суммы.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">4</td>\n",
    "    <td class=\"tg-0lax\">Я не буду платить за обещанный платеж</td>\n",
    "    <td class=\"tg-0lax\">Обещанный платеж</td>\n",
    "    <td class=\"tg-0lax\">Распознать: \"отказывается от факта\", \"хочет отключить\"</td>\n",
    "    <td class=\"tg-0lax\">Случаи с \"не хочу\", \"не буду\" классифицировать как \"Хочу отключить услугу\" - переобучить существующую модель</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Так как реальных данных нет, работу я решил продемонстрировать на маленьком датасете состоящим из смс-сообщений, размеченном на spam/ham. Далее работа будет вестись с ним.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "План исследования:\n",
    "1. Тест классических линейных алгоритмов в sklearn\n",
    "2. Vowpal Wabbit. Использует линейные алгоритмы. Удобна для работы с текстом, подходит для онлайн-обучения.\n",
    "3. Fasttext. Под капотом нейронная сеть с софтмаксом в качестве функции потерь. Встроенный метод разбиения на буквенные n-граммы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Тест классических линейных алгоритмов в sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем для обучения метод мешка слов созданный по методу TF-IDF. Результатом будет являться матрица объекты-признаки с весами, учитывающих как частоту слова в выборке, так и частоту слова в разных текстах (обратная частота).\n",
    "\n",
    "Лемматизацию проводить не будем, так как очевидно, что преведение слов к их начальным формам помешает отличать разные категории запросов с участием одних и тех же слов.\n",
    "\n",
    "В качестве тестритуемых моделей будем проверять логистическую регрессию, линейный классификатор, линейный SVM, а так же наивный баессовский классификатор. Все они хорошо показывают себя в задачах классификации текстов. Они хорошо масштабируются, могут работать с большим количеством признаков, на очень больших выборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sys\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные. Датасет состоит из 5575 смс-сообщений, 744 из них помечены как спам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SMSSpamCollection.txt', encoding='UTF-8') as f:\n",
    "    texts = f.read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выполним предобработку. Приведем к нижнему регистру, удалим цифры, пунктуацию.\n",
    "\n",
    "texts = texts.lower()\n",
    "texts = re.sub(r'\\d+', '', texts)\n",
    "texts = texts.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# Получим метки\n",
    "\n",
    "texts = texts.split('\\n')\n",
    "labels = [0 if 'ham' in i else 1 for i in texts]\n",
    "\n",
    "# Уберем метки из текстов\n",
    "\n",
    "texts = [i.replace('ham', '') for i in texts]\n",
    "texts = [i.replace('spam', '') for i in texts]\n",
    "texts = [i.replace('\\t', '') for i in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разобъем выборку на обучение и тест\n",
    "\n",
    "train_documents, test_documents, train_labels, test_labels = train_test_split(texts, \n",
    "                                                                              labels, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оценка качества работы разных классификаторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_classifier(vectorizer, transformer, classifier):\n",
    "    return Pipeline(\n",
    "            [(\"vectorizer\", vectorizer),\n",
    "            (\"transformer\", transformer),\n",
    "            (\"classifier\", classifier)]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "0.8382421063779119\n",
      "\n",
      "\n",
      "<class 'sklearn.svm.classes.LinearSVC'>\n",
      "0.9470760424800648\n",
      "\n",
      "\n",
      "<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\n",
      "0.9517620670774916\n",
      "\n",
      "\n",
      "<class 'sklearn.naive_bayes.MultinomialNB'>\n",
      "0.7927382830392253\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Тестируем классификаторы, оцениваем на кросс-валидации с помощью площади под ROC-AUC кривой\n",
    "\n",
    "roc_auc = metrics.make_scorer(metrics.roc_auc_score)\n",
    "\n",
    "for clf in [LogisticRegression, LinearSVC, SGDClassifier, MultinomialNB]:\n",
    "    print(clf)\n",
    "    print(cross_val_score(text_classifier(CountVectorizer(), \n",
    "                                          TfidfTransformer(), \n",
    "                                          clf()), train_documents, \n",
    "                                          train_labels, scoring=roc_auc).mean())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оценка использования n-грамм\n",
    "\n",
    "Далее применим n-граммы и проверим вариацию качества на кросс-валидации. Потестим на только биграммах, затем униграммах и биграммах, затем униграммах, биграммах и триграммах.\n",
    "\n",
    "Кроме того, учитывая наличие большого количества опечаток в текстах, в дальнейшем полезно попробовать применить буквенные n-граммы, которые могут помочь улучшить классификацию текстов с опечатками. Данный метод встроен в fasttext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "Ngram range: [2, 2]\n",
      "Cross-val-score roc-auc score: 0.5924\n",
      "\n",
      "Ngram range: [1, 2]\n",
      "Cross-val-score roc-auc score: 0.7926\n",
      "\n",
      "Ngram range: [1, 3]\n",
      "Cross-val-score roc-auc score: 0.7463\n",
      "\n",
      "<class 'sklearn.svm.classes.LinearSVC'>\n",
      "Ngram range: [2, 2]\n",
      "Cross-val-score roc-auc score: 0.8660\n",
      "\n",
      "Ngram range: [1, 2]\n",
      "Cross-val-score roc-auc score: 0.9491\n",
      "\n",
      "Ngram range: [1, 3]\n",
      "Cross-val-score roc-auc score: 0.9506\n",
      "\n",
      "<class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>\n",
      "Ngram range: [2, 2]\n",
      "Cross-val-score roc-auc score: 0.8959\n",
      "\n",
      "Ngram range: [1, 2]\n",
      "Cross-val-score roc-auc score: 0.9577\n",
      "\n",
      "Ngram range: [1, 3]\n",
      "Cross-val-score roc-auc score: 0.9635\n",
      "\n",
      "<class 'sklearn.naive_bayes.MultinomialNB'>\n",
      "Ngram range: [2, 2]\n",
      "Cross-val-score roc-auc score: 0.7455\n",
      "\n",
      "Ngram range: [1, 2]\n",
      "Cross-val-score roc-auc score: 0.7403\n",
      "\n",
      "Ngram range: [1, 3]\n",
      "Cross-val-score roc-auc score: 0.7141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf in [LogisticRegression, LinearSVC, SGDClassifier, MultinomialNB]:\n",
    "    print(clf)\n",
    "    for i in [[2,2], [1,2], [1,3]]:\n",
    "        print('Ngram range:', i)\n",
    "        res = cross_val_score(text_classifier(CountVectorizer(ngram_range=(i)), TfidfTransformer(), \n",
    "                                              clf()), train_documents, \n",
    "                                              train_labels, scoring=roc_auc, cv=3).mean()\n",
    "        print('Cross-val-score roc-auc score: %.4f\\n' % res)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее провалидируем лучшую модель на отложенной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDclassificator ROC-AUC: 0.9774868314424635\n",
      "SVC classificator ROC-AUC: 0.9795812758420053\n"
     ]
    }
   ],
   "source": [
    "# Посчитаем площадь под ROC-AUC кривой для SGD и SVC классификаторов на отложенной выборке\n",
    "\n",
    "SGD_clf = text_classifier(CountVectorizer(ngram_range=([1, 3])), TfidfTransformer(), SGDClassifier())\n",
    "SGD_clf.fit(train_documents, train_labels)\n",
    "print('SGDclassificator ROC-AUC: ' + str(metrics.roc_auc_score(SGD_clf.predict(test_documents), test_labels)))\n",
    "\n",
    "svc_clf = text_classifier(CountVectorizer(ngram_range=([1, 3])), TfidfTransformer(), LinearSVC())\n",
    "svc_clf.fit(train_documents, train_labels)\n",
    "print('SVC classificator ROC-AUC: ' + str(metrics.roc_auc_score(svc_clf.predict(test_documents), test_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vowpal Wabbit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся библиотекой Vowpal Wabbit которая широко используется для работы с текстом и онлайн обучения моделей. В ней так же используются линейные модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию, которая будет приводить наши данные к формату, который переваривает Vowpal Wabbit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-1 |text discussed with your mother ah\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_vw_format(document, label=None):\n",
    "    '''Brings sample to vowpal wabbit format'''\n",
    "    \n",
    "    return str(label or '') + ' |text ' + document + '\\n'\n",
    "\n",
    "to_vw_format(train_documents[0], 1 if labels == 1 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приведем выборку к формату VW\n",
    "\n",
    "with open('train.vw', 'w', encoding=\"utf-8\") as vw_train_data:\n",
    "    for text, target in zip(train_documents, train_labels):\n",
    "        try:\n",
    "            vw_train_data.write(to_vw_format(text, 1 if target == 1 else -1))\n",
    "        except:\n",
    "            err = to_vw_format(text, target)\n",
    "            print(err)\n",
    "            break\n",
    "with open('test.vw', 'w', encoding=\"utf-8\") as vw_test_data:\n",
    "    for text in test_documents:\n",
    "        vw_test_data.write(to_vw_format(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим Vowpal Wabbit на сформированном файле. Зададим функцию потерь, которая показала лучшее значение на предыдущих тестах. Добавим n-граммы. Построенную модель сохраним в соответствующий файл model.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating 2-grams for all namespaces.\n",
      "Generating 3-grams for all namespaces.\n",
      "final_regressor = model.vw\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0  -1.0000   0.0000       13\n",
      "1.148252 1.296504            2            2.0   1.0000  -0.1386       34\n",
      "0.999481 0.850709            4            4.0   1.0000   0.0945       55\n",
      "0.775353 0.551225            8            8.0  -1.0000  -0.4509       25\n",
      "0.729443 0.683533           16           16.0  -1.0000  -0.9039       34\n",
      "0.694735 0.660028           32           32.0   1.0000  -0.1515       61\n",
      "0.453237 0.211738           64           64.0  -1.0000  -0.7939       37\n",
      "0.406101 0.358964          128          128.0  -1.0000  -1.0000       55\n",
      "0.298645 0.191189          256          256.0  -1.0000  -1.0000       22\n",
      "0.225954 0.153263          512          512.0  -1.0000  -1.0000       16\n",
      "0.164201 0.102448         1024         1024.0   1.0000   1.0000       55\n",
      "0.120917 0.077633         2048         2048.0  -1.0000  -1.0000       13\n",
      "0.082597 0.044276         4096         4096.0  -1.0000  -1.0000       16\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 4181\n",
      "passes used = 1\n",
      "weighted example sum = 4181.000000\n",
      "weighted label sum = -3037.000000\n",
      "average loss = 0.081199\n",
      "best constant = -0.726381\n",
      "best constant's loss = 0.472370\n",
      "total feature number = 182492\n"
     ]
    }
   ],
   "source": [
    "!vw -d train.vw --loss_function classic --ngram 2 --ngram 3 -f model.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим обученную модель на тестовой выборке, сохраним результат в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating 2-grams for all namespaces.\n",
      "Generating 3-grams for all namespaces.\n",
      "only testing\n",
      "predictions = test_predictions.txt\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = test.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "    n.a.     n.a.            1            1.0  unknown   1.0000       43\n",
      "    n.a.     n.a.            2            2.0  unknown  -1.0000       31\n",
      "    n.a.     n.a.            4            4.0  unknown  -1.0000       28\n",
      "    n.a.     n.a.            8            8.0  unknown  -1.0000       34\n",
      "    n.a.     n.a.           16           16.0  unknown  -1.0000       58\n",
      "    n.a.     n.a.           32           32.0  unknown  -1.0000       46\n",
      "    n.a.     n.a.           64           64.0  unknown   1.0000       73\n",
      "    n.a.     n.a.          128          128.0  unknown  -1.0000       25\n",
      "    n.a.     n.a.          256          256.0  unknown  -1.0000       58\n",
      "    n.a.     n.a.          512          512.0  unknown  -1.0000       49\n",
      "    n.a.     n.a.         1024         1024.0  unknown  -1.0000       40\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1394\n",
      "passes used = 1\n",
      "weighted example sum = 1394.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = n.a.\n",
      "total feature number = 56434\n"
     ]
    }
   ],
   "source": [
    "!vw -i model.vw -t -d test.vw -p test_predictions.txt --binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим полученные предсказания, вычислим AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9464469226963043"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction = None\n",
    "with open('test_predictions.txt') as pred_file:\n",
    "    test_prediction = [float(label) \n",
    "                             for label in pred_file.readlines()]\n",
    "\n",
    "auc = metrics.roc_auc_score(test_labels, test_prediction)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_l = list(map(lambda x: 0 if x == -1 else 1, test_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9808917197452229"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_score(test_labels, test_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8953488372093024"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.recall_score(test_labels, test_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VW так же удобно использовать при многоклассовой классификации, для этого при обучении на соответсвующей выборке (классы должны быть нумерованы начиная с 1) передается параметр --oaa ('one against all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настраиваемые гиперпараметры, которые оказывают существенное влияние на качество модели:\n",
    "\n",
    "\n",
    "- темп обучения (-l, по умолчанию 0.5) – коэффициент перед изменением весов модели при каждом изменении\n",
    "- степень убывания темпа обучения (--power_t, по умолчанию 0.5) – на практике проверено, что если темп обучения уменьшается при увеличении числа итераций стохастического градиентного спуска, то минимум функции находится лучше\n",
    "- функция потерь (--loss_function) – от нее, по сути, зависит обучаемый алгоритм. Про функции mпотерь в документации\n",
    "- регуляризация (-l1) – тут надо обратить внимание на то, что в VW регуляризация считается для каждого объекта, поэтому коэффициенты регуляризации обычно берутся малыми, около  10−20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучения классификатора воспользуемся библиотекой fasttext, в основе лежит использование буквенных n-грамм, что позволяет алгоритму успешно работать с текстами, содержащими ошибки, а так же незнакомые слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SMSSpamCollection.txt', encoding='UTF-8') as f:\n",
    "    texts = f.read() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для улучшения классификации следует применять простой предпроцессинг вроде приведения к нижнему регистру, удаление знаков препинания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выполним предобработку. Приведем к нижнему регистру, удалим цифры, пунктуацию.\n",
    "\n",
    "texts = texts.lower()\n",
    "texts = re.sub(r'\\d+', '', texts)\n",
    "texts = texts.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# Добавим метки в соответствии с требованиями fasttext\n",
    "\n",
    "texts = texts.replace('ham', '__label__ham ')\n",
    "texts = texts.replace('spam', '__label__spam ')\n",
    "texts = texts.replace('\\t', '')\n",
    "texts = texts.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разобъем выборку на обучение и тест\n",
    "\n",
    "train_documents, test_documents = train_test_split(texts, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_documens.txt', 'w', encoding='UTF-8') as f:\n",
    "    for i in train_documents:\n",
    "        f.write(i + '\\n')\n",
    "#         f.writelines(train_documents)\n",
    "with open('test_documens.txt', 'w', encoding='UTF-8') as f:\n",
    "    for i in test_documents:\n",
    "        f.write(i + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучим модель\n",
    "\n",
    "model = fasttext.train_supervised(input='train_documens.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1394, 0.9813486370157819, 0.9813486370157819)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получим значения точности, полноты на отложенной выборке:\n",
    "\n",
    "model.test(\"test_documens.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__ham', '__label__spam'), array([1.00000858e+00, 1.13843689e-05]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Выведем предсказание для рандомного текста\n",
    "\n",
    "\n",
    "model.predict(\"Why not put knives in the dishwasher?\", k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настраиваевым гиперпараметром модели является число итераций по выборке epochs, которое по-умолчанию равно 5, что в зависимости от размера выборки может быть недостаточно.\n",
    "\n",
    "\n",
    "Еще одним гиперпараметром является learning rate или шаг обучения, которая влияет на скорость обучения и принимает значения 0.1 - 1. 0 - модель не меняется вообще. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увеличим количество итераций до 11, выставим learning rate 0.5. Данные параметры можно понастраивать в paramgrid где можно перебирать значения гиперпараметров с заданным шагом, а затем сравнивать качество алгоритмов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(input=\"train_documens.txt\", epoch=11, lr=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1394, 0.9813486370157819, 0.9813486370157819)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test(\"test_documens.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fasttext также позволяет применять n-граммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(input=\"train_documens.txt\", epoch=11, lr=0.1, wordNgrams=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1394, 0.9799139167862266, 0.9799139167862266)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test(\"test_documens.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритмы sklearn заметно уступают VW и fasttext.\n",
    "\n",
    "Лучшие значения метрик на отложенной выборке показывает fasttest. Хотя конечно же не достаточно, что бы однозначно говорить, что fasttest VW действительно лучше работает на данном распределении чем алгоритм fasttext."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
