{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача: Углубить обработку запросов пользователей в чат-боте технической поддержки и категоризировать их по заданным, более узким в отличии от уже работающих, критериям.\n",
    "\n",
    "Описание текущей ситуации: на данный момент имеются рабочие модели, которые успешно классифицируют запросы пользователей по таким темам как \"Обещанный платеж\", \"Куда делись деньги\", \"Как подключить интернет\", \"Хочу поменять тариф\", и т.д.\n",
    "\n",
    "Стоит задача углубить эту классификацию. Далее представлены конкретные задачи от заказчика.\n",
    "\n",
    "---\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;}\n",
    ".tg .tg-lboi{border-color:inherit;text-align:left;vertical-align:middle}\n",
    ".tg .tg-0lax{text-align:left;vertical-align:top}\n",
    ".tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\" style=\"undefined;table-layout: fixed; width: 759px\">\n",
    "<colgroup>\n",
    "<col style=\"width: 27px\">\n",
    "<col style=\"width: 125px\">\n",
    "<col style=\"width: 105px\">\n",
    "<col style=\"width: 171px\">\n",
    "<col style=\"width: 331px\">\n",
    "</colgroup>\n",
    "  <tr>\n",
    "    <th class=\"tg-lboi\">№</th>\n",
    "    <th class=\"tg-lboi\">Запрос пользователя</th>\n",
    "    <th class=\"tg-0lax\">Результат текущего фреймворка</th>\n",
    "    <th class=\"tg-0lax\">Требуемый результат</th>\n",
    "    <th class=\"tg-0lax\"><center>Комментарий</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-lboi\">1</td>\n",
    "    <td class=\"tg-lboi\">Подключен ли у меня мобильный интернет</td>\n",
    "    <td class=\"tg-0lax\">Как подключить интернет</td>\n",
    "    <td class=\"tg-0lax\">Классифицировать как \"подключен ли мобильный интернет\"</td>\n",
    "    <td class=\"tg-0lax\">Создадим новый классификатор \"Подключен ли \\ Есть ли\" на том же уровне что и классификатор \"Хочу отключить услугу/опцию/подписку\". Частицу \"ли\" будем добавлять к слову перед ней. Модель будет обрабатывать запросы на получение информации.<br>Далее запрос будет классифицироваться на наличие в нем названия услуги</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-lboi\">2</td>\n",
    "    <td class=\"tg-lboi\">Не ноступен обещенный платеж. Почему</td>\n",
    "    <td class=\"tg-0lax\">Обещанный платеж</td>\n",
    "    <td class=\"tg-0lax\">Из фразы понятен контекст: \"Почему не доступен ОП\"</td>\n",
    "    <td class=\"tg-0lax\">Решение: Не менять модель, а просто после классификации в \"Обещанный платеж\" проверять содержание сообщения на предмет слов \"Почему\", \"не доступен\" и подобных.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">3</td>\n",
    "    <td class=\"tg-0pky\">За что сегодня снялись 15р?</td>\n",
    "    <td class=\"tg-0lax\">Куда делись деньги</td>\n",
    "    <td class=\"tg-0lax\">\"Начисления за подписка: 21.10.2019 - 15р\"</td>\n",
    "    <td class=\"tg-0lax\">Простое решение, которое приходит в голову - после классификации искать в тексте слова \"сегодня\", \"вчера\" и даты, а так же суммы. Можно так же искать и только суммы.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">4</td>\n",
    "    <td class=\"tg-0lax\">Я не буду платить за обещанный платеж</td>\n",
    "    <td class=\"tg-0lax\">Обещанный платеж</td>\n",
    "    <td class=\"tg-0lax\">Распознать: \"отказывается от факта\", \"хочет отключить\"</td>\n",
    "    <td class=\"tg-0lax\">Случаи с \"не хочу\", \"не буду\" классифицировать как \"Хочу отключить услугу\" - переобучить существующую модель</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала потестим модели в sklearn, затем обучим модель в VW."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем для обучения метод мешка слов созданный по методу TF-IDF. Результатом будет являться матрица объекты-признаки с весами, учитывающих как частоту слова в выборке, так и частоту слова в разных текстах (обратная частота).\n",
    "\n",
    "Лемматизацию проводить не будем, так как очевидно, что преведение слов к их начальным формам помешает отличать разные категории запросов с участием одних и тех же слов.\n",
    "\n",
    "В качестве тестритуемых моделей будем проверять логистическую регрессию, линейный классификатор, линейный SVM, а так же наивный баессовский классификатор. Все они хорошо показывают себя в задачах классификации текстов. Они хорошо масштабируются, могут работать с большим количеством признаков, на очень больших выборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, что у нас есть выборка с текстами и метками классов и мы разбили ее на обучение и контроль.\n",
    "\n",
    "Тогда texts - обучающая выборка, labels - вектор соответствующих меток классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оценка качества работы разных классификаторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_classifier(vectorizer, transformer, classifier):\n",
    "    return Pipeline(\n",
    "            [(\"vectorizer\", vectorizer),\n",
    "            (\"transformer\", transformer),\n",
    "            (\"classifier\", classifier)]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестируем классификаторы, оцениваем на кросс-валидации с помощью f-меры\n",
    "\n",
    "f1 = metrics.make_scorer(metrics.f1_score)\n",
    "\n",
    "for clf in [LogisticRegression, LinearSVC, SGDClassifier]:\n",
    "    print(clf)\n",
    "    print(cross_val_score(text_classifier(CountVectorizer(), TfidfTransformer(), \n",
    "                                          clf()), texts, labels, scoring=f1).mean())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оценка использования n-грамм\n",
    "\n",
    "Далее применим n-граммы и проверим вариацию качества на кросс-валидации. Потестим на только биграммах, затем униграммах и биграммах, затем униграммах, биграммах и триграммах.\n",
    "\n",
    "Кроме того, учитывая наличие большого количества опечаток в текстах, в дальнейшем полезно попробовать применить буквенные n-граммы, которые могут помочь улучшить классификацию текстов с опечатками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf in [LogisticRegression, LinearSVC, SGDClassifier]:\n",
    "    print(clf)\n",
    "    for i in [[2,2], [1,2], [1,3]]:\n",
    "        print('Ngram range:', i)\n",
    "        res = cross_val_score(text_classifier(CountVectorizer(ngram_range=(i)), TfidfTransformer(), \n",
    "                                          clf()), texts, labels, scoring=f1, cv=3).mean()\n",
    "        print('Cross-val-score f1: %.4f\\n' % res)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее провалидируем лучшую модель на отложенной выборке. Дальнейшие шаги зависят от того, обнаруживается ли переобучение на этапе валидации и устраивает ли качество работы алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vowpal Wabbit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае дальнейшего использования линейных моделей будем пользоваться библиотекой Vowpal Wabbit которая широко используется для работы с текстом и онлайн обучения моделей. В ней так же используются линейные модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведем наши данные к формату Vowpal Wabbit, при этом оставляя только слова не короче 2 символов. На данном этапе уместно проводить предобработку данных: применить регулярные выражения, удалить стоп-слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_vw_format(document, label=None):\n",
    "    return str(label or '') + ' |text ' + ' '.join(re.findall('\\w{2,}', document.lower())) + '\\n'\n",
    "\n",
    "to_vw_format(text, 1 if target == 1 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приведем выборку к формату VW\n",
    "\n",
    "train_documents, test_documents, train_labels, test_labels = \\\n",
    "    train_test_split(all_documents, all_targets, random_state=7)\n",
    "    \n",
    "with open('train.vw', 'w') as train_data:\n",
    "    for text, target in zip(train_documents, train_labels):\n",
    "        try:\n",
    "            vw_train_data.write(to_vw_format(text, target))\n",
    "        except:\n",
    "            err = to_vw_format(text, target)\n",
    "            break\n",
    "with open('test.vw', 'w', encoding=\"utf-8\") as test_data:\n",
    "    for text in test_documents:\n",
    "        vw_test_data.write(to_vw_format(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим Vowpal Wabbit на сформированном файле. Зададим функцию потерь, которая показала лучшее значение на предыдущих тестах, пока пусть это будет  значение hinge (линейный SVM), добавим n-граммы. Построенную модель сохраним в соответствующий файл model.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!vw -d train_data.vw --loss_function hinge --ngram 2 -f news_data/model.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим обученную модель на тестовой выборке, сохраним результат в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!vw -i model.vw -t -d test.vw -p test_predictions.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим полученные предсказания, вычислим AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = None\n",
    "with open('../../data/news_data/20news_test_predictions.txt') as pred_file:\n",
    "    test_prediction = [float(label) \n",
    "                             for label in pred_file.readlines()]\n",
    "\n",
    "auc = roc_auc_score(test_labels, test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VW так же удобно использовать при многоклассовой классификации, для этого при обучении на соответсвующей выборке (классы должны быть нумерованы начиная с 1) передается параметр --oaa ('one against all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настраиваемые гиперпараметры, которые оказывают существенное влияние на качество модели:\n",
    "\n",
    "\n",
    "- темп обучения (-l, по умолчанию 0.5) – коэффициент перед изменением весов модели при каждом изменении\n",
    "- степень убывания темпа обучения (--power_t, по умолчанию 0.5) – на практике проверено, что если темп обучения уменьшается при увеличении числа итераций стохастического градиентного спуска, то минимум функции находится лучше\n",
    "- функция потерь (--loss_function) – от нее, по сути, зависит обучаемый алгоритм. Про функции mпотерь в документации\n",
    "- регуляризация (-l1) – тут надо обратить внимание на то, что в VW регуляризация считается для каждого объекта, поэтому коэффициенты регуляризации обычно берутся малыми, около  10−20."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
